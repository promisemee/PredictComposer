{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint \n",
    "from datetime import datetime \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, Activation, MaxPooling2D, GRU, Reshape, BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preproecssing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch csv files\n",
    "test_dir = 'test_image'\n",
    "train_dir = 'train_image'\n",
    "\n",
    "train_csv = \"csv/train_data.csv\"\n",
    "test_csv = \"csv/test_data.csv\"\n",
    "\n",
    "train = pd.DataFrame(data=pd.read_csv(train_csv,dtype = str, error_bad_lines=False))\n",
    "test = pd.DataFrame(data=pd.read_csv(test_csv,dtype = str, error_bad_lines=False))\n",
    "\n",
    "#Drop composers out of list\n",
    "List = ['Ludwig van Beethoven', 'Wolfgang Amadeus Mozart', 'Johann Sebastian Bach', 'Franz Schubert', 'Frédéric Chopin']\n",
    "train = train[train['composer'].isin(List)]\n",
    "test = test[test['composer'].isin(List)]\n",
    "\n",
    "num_labels = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create datagenerator\n",
    "traingen=ImageDataGenerator(rescale=1./255, validation_split = 0.1)\n",
    "testgen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator=traingen.flow_from_dataframe(\n",
    "      dataframe=train,\n",
    "      directory = \"train_image/\",\n",
    "      x_col=\"image_file\",\n",
    "      y_col=\"composer\",\n",
    "      subset=\"training\",\n",
    "      batch_size=32,\n",
    "      seed=42,\n",
    "      shuffle=True,\n",
    "      class_mode=\"categorical\",\n",
    "      target_size=(32,96))\n",
    "\n",
    "validation_generator = traingen.flow_from_dataframe(\n",
    "    dataframe=train,\n",
    "    directory = \"train_image/\",\n",
    "    x_col=\"image_file\",\n",
    "    y_col=\"composer\",\n",
    "    subset=\"validation\",\n",
    "    target_size=(32,96),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator=testgen.flow_from_dataframe(\n",
    "  dataframe=test,\n",
    "  directory = \"test_image/\",\n",
    "  x_col=\"audio_file\",\n",
    "  y_col=\"composer\",\n",
    "  batch_size=32,\n",
    "  seed=42,\n",
    "  shuffle=True,\n",
    "  class_mode=\"categorical\",\n",
    "  target_size=(32,96))\n",
    "\n",
    "STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID = test_generator.n//test_generator.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoder for SVM\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "onehotencoder = OneHotEncoder(handle_unknown='ignore') \n",
    "enc_df = pd.DataFrame(onehotencoder.fit_transform(train[['composer']]).toarray())\n",
    "train = train.join(enc_df)\n",
    "onehotencoder = OneHotEncoder(handle_unknown='ignore') \n",
    "enc_df = pd.DataFrame(onehotencoder.fit_transform(test[['composer']]).toarray())\n",
    "test = test.join(enc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_image\n",
    "folder = Path(\"train_image/\")\n",
    "dirs = folder.glob(\"*\")\n",
    "labels_dict = {'Johann Sebastian Bach': 3 , 'Frédéric Chopin': 2, 'Wolfgang Amadeus Mozart': 4, \n",
    "               'Ludwig van Beethoven': 0, 'Franz Schubert': 1}\n",
    "\n",
    "image_data = []\n",
    "labels = [] \n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    img_path = Path(path+\"train_image2/\"+row[\"image_file\"])\n",
    "    img = image.load_img(img_path, target_size = (32,96))\n",
    "    img_array = image.img_to_array(img)\n",
    "    image_data.append(img_array)\n",
    "    label = row[[2,3,4,5,6]].to_numpy()\n",
    "    labels.append(label)\n",
    "\n",
    "## Convert data into numpy array\n",
    "\n",
    "train_data = np.array(image_data, dtype='float32')/255.0\n",
    "labels = np.array(labels)\n",
    "train_data = train_data.reshape(11633, 32*96*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, labels, test_size=0.1, random_state=42)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train SVM\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = LinearSVC()\n",
    "y_train = np.argmax(y_train, axis = 1)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_train)\n",
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict SVM\n",
    "y_test = np.argmax(y_test, axis = 1)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN structure : 4-2dlayers & 2 connected layers\n",
    "def buildCNN(num_labels, layers, weight=None):\n",
    "    model = Sequential()\n",
    "    \n",
    "    channel_axis = 3\n",
    "    \n",
    "    model.add(Conv2D(layers[0], (3, 3), strides=(1, 1), input_shape = (32,96,3), padding = \"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=channel_axis))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Conv2D(layers[1], (3, 3), padding=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=channel_axis))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Conv2D(layers[2], (3, 3), padding=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=channel_axis))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Conv2D(layers[3], (3, 3), padding=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=channel_axis))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.1))\n",
    "        \n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(rate=0.5))\n",
    "\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "\n",
    "    model.add(Dense(num_labels))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    if weight is None:\n",
    "        return model\n",
    "\n",
    "    else:\n",
    "        model.load_weights(weight)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN Model\n",
    "layers = [32, 64, 128, 128]\n",
    "modelCNN = buildCNN(num_labels, layers)\n",
    "modelCNN.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "modelCNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train CNN\n",
    "start = datetime.now()\n",
    "\n",
    "num_epochs = 150\n",
    "\n",
    "cp1 = ModelCheckpoint(filepath='saved_models/weights.best.basic_cnn_test.hdf5', verbose=1, save_best_only=True)\n",
    "es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=10)\n",
    "historyCNN = modelCNN.fit_generator(generator=train_generator, steps_per_epoch=STEP_SIZE_TRAIN, validation_data=validation_generator, \n",
    "                              validation_steps = STEP_SIZE_VALID, callbacks = [cp1, es], epochs=num_epochs)\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)\n",
    "model.save('saved_models/cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate model\n",
    "print(modelCNN.evaluate_generator(train_generator))\n",
    "print(modelCNN.evaluate_generator(validation_generator))\n",
    "print(modelCNN.evaluate_generator(test_generator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CRNN model : 3-2d convolutional layers with 2 RNN layers\n",
    "def buildCRNN(num_labels, weight=None):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), strides=(1, 1), input_shape = (32,96,3), padding = \"same\"))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(rate=0.1))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(rate=0.1))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "    model.add(MaxPooling2D((3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(rate=0.1))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(rate=0.5))\n",
    "\n",
    "    model.add(Reshape((16,128)))\n",
    "    \n",
    "    model.add(GRU(32, return_sequences=True))\n",
    "    model.add(GRU(32, return_sequences=False))\n",
    "    model.add(Dropout(rate=0.3))\n",
    "    \n",
    "    model.add(Dense(num_labels))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    if weight is None:\n",
    "        return model\n",
    "\n",
    "    else:\n",
    "        model.load_weights(weight)\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build CRNN\n",
    "modelCRNN = buildCRNN(num_labels)\n",
    "modelCRNN.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "modelCRNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train CRNN\n",
    "start = datetime.now()\n",
    "num_epochs = 150\n",
    "\n",
    "checkpointer2 = ModelCheckpoint(filepath='saved_models/weights.best.basic_crnn_test.hdf5', verbose=1, save_best_only=True)\n",
    "es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=10)\n",
    "historyCRNN = modelCRNN.fit_generator(generator=train_generator, steps_per_epoch=STEP_SIZE_TRAIN, validation_data=validation_generator, \n",
    "                                validation_steps=STEP_SIZE_VALID, callbacks = [checkpointer2, es], epochs=num_epochs)\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)\n",
    "model2.save('saved_models/crnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate model\n",
    "print(modelCRNN.evaluate_generator(train_generator))\n",
    "print(modelCRNN.evaluate_generator(validation_generator))\n",
    "print(modelCRNN.evaluate_generator(test_generator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix (Testing CRNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "Y_pred = modelCRNN.predict(train_generator)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "cm = confusion_matrix(y_pred, train_generator.classes)\n",
    "\n",
    "classes = ['Franz Schubert', 'Frédéric Chopin', 'Johann Sebastian Bach', 'Ludwig van Beethoven', 'Wolfgang Amadeus Mozart']\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.imshow(cm,interpolation='none',cmap='Blues')\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "for (i, j), z in np.ndenumerate(cm):\n",
    "       plt.text(j, i, z, ha='center', va='center')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
